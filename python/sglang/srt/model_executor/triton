ForwardBatch contents:
forward_mode: ForwardMode.DECODE
input_ids: tensor([ 6575,    13, 29889,   297], device='cuda:0')
positions: tensor([10, 10, 10, 10], device='cuda:0')
input_embeds: None
sampling_info: SamplingBatchInfo(temperatures=tensor([[1.]], device='cuda:0'), top_ps=tensor([1.], device='cuda:0'), top_ks=tensor([1], device='cuda:0', dtype=torch.int32), min_ps=tensor([0.], device='cuda:0'), is_all_greedy=True, need_min_p_sampling=False, vocab_size=32000, grammars=None, sampling_info_done=None, logit_bias=None, vocab_mask=None, apply_mask=None, penalizer_orchestrator=<sglang.srt.sampling.penaltylib.orchestrator.BatchedPenalizerOrchestrator object at 0x7f71627a7d90>, linear_penalties=None, scaling_penalties=None, device='cuda')
return_logprob: False
top_logprobs_nums: None
spec_info: {'prev_mode': <ForwardMode.EXTEND: 2>, 'sample_output': tensor([[1.3409e-08, 1.2597e-08, 2.4157e-03,  ..., 4.9165e-07, 1.8726e-08,
         2.6568e-07]], device='cuda:0'), 'scores': tensor([[0.0906, 0.0813, 0.0529, 0.0481]], device='cuda:0'), 'score_list': [tensor([[[0.0906, 0.0813, 0.0529, 0.0481]]], device='cuda:0')], 'token_list': [tensor([[ 6575,    13, 29889,   297]], device='cuda:0')], 'origin_score_list': [tensor([[0.0906, 0.0813, 0.0529, 0.0481]], device='cuda:0')], 'parents_list': [tensor([[-1,  0,  1,  2,  3]], device='cuda:0')], 'cache_list': [tensor([11, 12, 13, 14], device='cuda:0', dtype=torch.int32)], 'iter': 1, 'hidden_states': tensor([[ 1.4375, -2.2090,  1.2959,  ..., -0.5654,  0.5142, -0.2441],
        [ 1.4375, -2.2090,  1.2959,  ..., -0.5654,  0.5142, -0.2441],
        [ 1.4375, -2.2090,  1.2959,  ..., -0.5654,  0.5142, -0.2441],
        [ 1.4375, -2.2090,  1.2959,  ..., -0.5654,  0.5142, -0.2441]],
       device='cuda:0', dtype=torch.float16), 'verified_id': tensor([372], device='cuda:0', dtype=torch.int32), 'positions': tensor([10, 10, 10, 10], device='cuda:0'), 'accept_length': None, 'has_finished': False, 'unfinished_index': None, 'topk': 4, 'num_verify_token': 16, 'spec_steps': 3}
attn_metadata: None
kv_caches: None
kv_cache_dtype: None
kv_cache_fp8_scale: None
kv_cache_fp8_scale_inv: None
out: LogitsProcessorOutput(next_token_logits=tensor([[-2.5977e+00, -1.3438e+00,  8.9297e+00,  ...,  2.2534e-01,
         -2.1777e+00,  9.4873e-01],
        [        nan,         nan,         nan,  ...,         nan,
                 nan,         nan],
        [-3.5900e+02,  3.7800e+02, -5.3188e+01,  ...,  7.2550e+02,
          1.5742e+00, -3.8100e+02],
        [ 1.2656e+02,  3.1925e+02, -7.5000e+01,  ..., -1.6962e+02,
          1.8150e+02,  7.3250e+01]], device='cuda:0'), hidden_states=tensor([[ 9.9072e-01, -2.2441e+00,  2.1641e+00,  ..., -4.0918e-01,
          7.1582e-01, -8.7842e-01],
        [        nan,         nan,         nan,  ...,         nan,
                 nan,         nan],
        [ 2.0275e+02,  2.7828e+01, -1.7425e+02,  ..., -5.5969e+01,
         -5.5406e+01, -6.1250e+02],
        [-1.5662e+02,  9.1875e+01, -2.0375e+02,  ...,  1.6712e+02,
          3.2781e+01, -6.4812e+01]], device='cuda:0', dtype=torch.float16), next_token_logprobs=None, next_token_top_logprobs_val=None, next_token_top_logprobs_idx=None, input_token_logprobs=None, input_top_logprobs_val=None, input_top_logprobs_idx=None)
